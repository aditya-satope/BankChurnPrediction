# Customer Churn Prediction - Kaggle Competition

## Overview

Hello everyone! ðŸ‘‹ Step into my Kaggle project where I excelled in the Customer Churn Prediction competition! ðŸš€ Achieving an outstanding score of 88.5%, I came remarkably close to the top spot with a dazzling 90.02%!

### Data Overview

The competition presented a dataset featuring various customer attributes such as ID, CustomerId, Surname, CreditScore, Geography, Gender, Age, Tenure, Balance, and NumOfProd. Our mission was to predict whether a customer would decide to part ways with our services.

## What I learned?

Now, let's shift gears from the amusing tone to a more determined discussion about the insights gained during this project:

1. **Binning Methods:**
   Explored and implemented effective binning methods, specifically with age data. This technique involved categorizing ages into meaningful groups, proving valuable for refining model predictions. ðŸŽ©

2. **Addressing Skewed Datasets:**
   Tackled the challenge of skewed data with a strategic approach. Employed techniques such as SMOTE, Resampling, and Stratified K-Fold to harmonize the data distribution and enhance model performance.

## Methodology

Transitioning to the methodology section, here's how I navigated through the competition:

### Initial Data Exploration
Initiated the project with a meticulous examination of the dataset. While no missing data surfaced, certain features exhibited skewed patterns, prompting further investigation.

### Feature Engineering
Applied feature transformations, including age binning and the creation of new features by combining gender and geography. This step aimed to provide the models with richer information.

### Addressing Skewed Data
Mitigated the effects of data skewness using advanced techniques like SMOTE, Resampling, and Stratified K-Fold, ensuring a more balanced representation in the model training process.

### Model Selection and Ensemble
Leveraged PyCaret to identify optimal modelsâ€”LightGBM and CatBoost emerged as standout performers. Rigorous hyperparameter optimization was conducted, culminating in the creation of an ensemble model to harness the strengths of both.

## Dive into the Code

Feel free to explore the code and witness the strategic implementation of these methodologies! If you have any questions, I'm here to help. Let's continue coding, and may the data be ever in your favor! ðŸš€ðŸ“Š
